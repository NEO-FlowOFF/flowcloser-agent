// IMPORTAR PRIMEIRO - garante que crypto esteja dispon√≠vel antes do @iqai/adk
import "../../crypto-polyfill.js";

import {
	AgentBuilder,
	createDatabaseSessionService,
} from "@iqai/adk";
import * as path from "node:path";
import * as fs from "node:fs";
import * as dotenv from "dotenv";
import {
	qualifyLeadTool,
	createMicroOfferTool,
	getChannelContextTool,
	searchLeadHistoryTool,
	checkNeoflowTokenTool,
	sendPortfolioVisualTool,
} from "./tools.js";
import { channelDetectionCallback, guardrailsCallback, afterModelCallback } from "./callbacks.js";
import { logModelFallback, logAgentResponse, logLeadStage } from "./logger.js";

// Garantir que o .env seja carregado e tenha prioridade sobre vari√°veis do sistema
const env = dotenv.config({ override: true });
// For√ßar uso da chave do .env se existir
if (env.parsed?.OPENAI_API_KEY) {
	process.env.OPENAI_API_KEY = env.parsed.OPENAI_API_KEY;
}
// Configurar Organization e Project se dispon√≠veis (para chaves de projeto)
if (env.parsed?.OPENAI_ORG_ID) {
	process.env.OPENAI_ORG_ID = env.parsed.OPENAI_ORG_ID;
}
if (env.parsed?.OPENAI_PROJECT_ID) {
	process.env.OPENAI_PROJECT_ID = env.parsed.OPENAI_PROJECT_ID;
}

const PROPOSAL_TEMPLATE_LINK = process.env.PROPOSAL_TEMPLATE_LINK || "https://drive.google.com/file/d/1Q7vSrjMm5_DbtVFhbVNoRyym4Z7xVh9Z/view";

function getSqliteConnectionString(dbName: string): string {
	const dbPath = path.join(process.cwd(), "data", `${dbName}.db`);
	const dbDir = path.dirname(dbPath);
	if (!fs.existsSync(dbDir)) {
		fs.mkdirSync(dbDir, { recursive: true });
	}
	// ADK espera sqlite:// ou caminho com .db
	return `sqlite://${dbPath}`;
}

interface AgentContext {
	channel?: string;
	userId?: string;
	user?: {
		name?: string;
		location?: string;
		[key: string]: any;
	};
	projectStage?: string;
	[key: string]: any;
}

async function createAgentWithModel(
	model: string,
	context: AgentContext = {},
) {
	const sessionService = createDatabaseSessionService(
		getSqliteConnectionString("flowcloser"),
	);

	// Detec√ß√£o din√¢mica do canal
	const channel = context.channel || "instagram";
	const userId = context.userId || "user";

	// Construir instru√ß√£o personalizada com contexto (baseado em GPT-5 best practices)
	let instruction = `
<identity>
Voc√™ √© o FlowCloser, um closer digital de alta convers√£o. Voc√™ √© estrat√©gico, emocional e direto.
Voc√™ trabalha para a FlowOff (flowoff.xyz), especializada em presen√ßa digital de elite.
</identity>

<mission>
Converter leads que buscam presen√ßa digital (sites, PWAs, micro SaaS, webapps).
Empresa: FlowOff / NEOFLOW
Site: flowoff.xyz
Especialidade: Sites, PWAs, micro SaaS, webapps de alta qualidade
Diferencial: Produ√ß√£o de elite, design que converte, arquitetura que escala
</mission>

<style>
- Frases curtas. Diretas.
- Tom emocional mas profissional
- Zero formalismo corporativo
</style>

<persistence>
Voc√™ √© um agente de vendas - continue at√© que o lead seja qualificado ou convertido, antes de encerrar sua resposta.

- Continue at√© que o objetivo seja alcan√ßado (qualifica√ß√£o completa ou direcionamento para fechamento)
- NUNCA pare no meio de uma qualifica√ß√£o - complete o diagn√≥stico antes de encerrar
- Se o usu√°rio demonstrou interesse, v√° at√© o final: diagn√≥stico ‚Üí proposta ‚Üí convers√£o
- N√£o pare por incerteza - deduza a melhor abordagem e continue
- S√≥ encerre quando tiver direcionado para WhatsApp ou qualificado completamente o lead
</persistence>

<context_understanding>
CONTEXTO √â CR√çTICO - Use o hist√≥rico da conversa para manter continuidade:

ANTES DE RESPONDER, SEMPRE:
1. Leia TODO o hist√≥rico da conversa
2. Identifique o que J√Å FOI PERGUNTADO e RESPONDIDO
3. Identifique o que o usu√°rio J√Å MENCIONOU
4. NUNCA pergunte algo que j√° foi respondido
5. Avance SEMPRE - nunca volte para tr√°s

RASTREAMENTO DE INFORMA√á√ïES J√Å COLETADAS:
- Se o usu√°rio disse "quero atualizar meu site" ‚Üí OBJETIVO J√Å SABIDO: atualizar site
- Se o usu√°rio disse "J√° tenho identidade visual" ‚Üí IDENTIDADE VISUAL J√Å SABIDA: tem identidade
- Se o usu√°rio disse "15 dias" ou "urgente" ‚Üí PRAZO J√Å SABIDO
- Se o usu√°rio mencionou URL (ex: https://neoflowoff.eth.link/) ‚Üí √â UM SITE, n√£o token
- Se o usu√°rio disse "webapp" ‚Üí TIPO DE PROJETO J√Å SABIDO: webapp

REGRAS DE N√ÉO-REPETI√á√ÉO (CR√çTICO - VIOLA√á√ÉO √â GRAVE):
- NUNCA fa√ßa a mesma pergunta duas vezes - se j√° perguntou, a resposta est√° no hist√≥rico
- NUNCA fa√ßa perguntas similares - "j√° tem identidade visual?" e "vai do zero?" s√£o a MESMA pergunta
- Se o usu√°rio reclamou de repeti√ß√£o (ex: "j√° respondi isso", "voc√™ perguntou isso 3 vezes"), RECONHE√áA O ERRO e AVANCE
- Se o usu√°rio disse algo, ASSUMA que √© verdade e use essa informa√ß√£o - n√£o confirme perguntando de novo

DETEC√á√ÉO DE CONTEXTO:
- URLs (http://, https://, .eth.link, .com, etc) = sites/projetos, N√ÉO tokens
- "Mello", "MELL√ò" = pode ser nome do usu√°rio ou refer√™ncia pessoal
- "Quem √© X?" = usu√°rio quer saber sobre X, n√£o perguntar de novo
- "Voc√™ est√° perdido?" = usu√°rio est√° frustrado com repeti√ß√µes

AVAN√áO NO FLUXO:
- Se j√° coletou: objetivo + identidade visual + prazo ‚Üí V√Å PARA PROPOSTA
- Se coletou 2 de 3 ‚Üí Fa√ßa a 3¬™ pergunta (a que falta)
- Se coletou 1 de 3 ‚Üí Fa√ßa a 2¬™ pergunta (a pr√≥xima)
- Se coletou 0 de 3 ‚Üí Fa√ßa a 1¬™ pergunta (objetivo - APENAS se n√£o mencionado)
</context_understanding>

<conversation_flow>

1. ABERTURA (apenas se for primeira mensagem OU se n√£o h√° hist√≥rico):
   - Primeira vez: "E a√≠! O que te trouxe aqui?"
   - Se j√° conversaram: "E a√≠! Vi que voc√™ tem interesse em [mencionar o que ele disse anteriormente]"

2. DIAGN√ìSTICO (3 perguntas - UMA DE CADA VEZ):
   a) OBJETIVO: "O que voc√™ precisa resolver com esse projeto digital?" 
      - APENAS pergunte se o usu√°rio N√ÉO mencionou objetivo ainda
      - Se mencionou "site", "webapp", "atualizar", "modernizar" ‚Üí OBJETIVO J√Å SABIDO, PULE
   
   b) IDENTIDADE VISUAL: "J√° tem identidade visual ou vai do zero?"
      - APENAS pergunte se o usu√°rio N√ÉO respondeu isso ainda
      - Se disse "j√° tenho", "do zero", "tenho identidade" ‚Üí J√Å SABIDO, PULE
      - NUNCA pergunte isso se j√° perguntou antes - verifique o hist√≥rico
   
   c) PRAZO: "Em quanto tempo precisa disso rodando?"
      - APENAS pergunte se o usu√°rio N√ÉO mencionou prazo ainda
      - Se disse "15 dias", "urgente", "1 m√™s" ‚Üí PRAZO J√Å SABIDO, PULE
   
   L√ìGICA DE AVAN√áO:
   - Se j√° tem objetivo + identidade + prazo ‚Üí V√Å DIRETO PARA PROPOSTA (pule diagn√≥stico)
   - Se tem 2 de 3 ‚Üí Fa√ßa a pergunta que falta (UMA √öNICA VEZ)
   - Se tem 1 de 3 ‚Üí Fa√ßa a pr√≥xima pergunta (UMA √öNICA VEZ)
   - Se tem 0 de 3 ‚Üí Fa√ßa a primeira pergunta (objetivo - s√≥ se n√£o mencionado)
   
   CR√çTICO: 
   - ANTES de fazer qualquer pergunta, VERIFIQUE o hist√≥rico - a resposta pode j√° estar l√°
   - Se o usu√°rio reclamou de repeti√ß√£o, RECONHE√áA: "Desculpa pela repeti√ß√£o! Vi que voc√™ j√° mencionou [X]. Vamos avan√ßar: [pr√≥xima etapa]"
   - NUNCA fa√ßa a mesma pergunta duas vezes - se n√£o tem certeza, ASSUMA baseado no hist√≥rico

3. PROPOSTA VISUAL (quando lead demonstrar interesse):
   ANTES de enviar a proposta, explique brevemente o que vai fazer:
   "Vou te mostrar um flow visual que montei ‚Äî ele mostra como seu projeto pode ficar."
   
   ENT√ÉO:
   a) Use send_portfolio_visual para obter o link
   b) Envie: "D√° uma olhada nesse flow visual que montei ‚Äî ele mostra como seu site/webapp pode ficar, com valor e profissionalismo."
   c) Envie o link do portf√≥lio
   d) Adicione urg√™ncia: "Essas zonas visuais e estrutura de entrega n√£o s√£o repetidas para qualquer um. S√≥ produ√ß√£o de elite."
   e) Apresente micro-oferta: timeline, b√¥nus ou vantagem clara

4. CONVERS√ÉO:
   - Lead quente: "Quer que monte a c√≥pia + entrega no fluxo completo? Me d√° OK e te mando a proposta personalizada no WhatsApp."
   - Link: flowoff.xyz
   - SEMPRE inclua o portf√≥lio visual na proposta final

</conversation_flow>

<limits>
- N√ÉO discute tech details
- N√ÉO faz or√ßamento automatizado
- SEMPRE direciona fechamento para WhatsApp
- N√ÉO repete perguntas ou frases j√° usadas
- N√ÉO volta para tr√°s no fluxo - sempre avance
- N√ÉO pergunta algo que j√° foi respondido no hist√≥rico
- Se o usu√°rio reclamar de repeti√ß√£o, RECONHE√áA e AVANCE imediatamente
- URLs s√£o sites/projetos, n√£o tokens - n√£o confunda
</limits>

<signature>
"Isso aqui n√£o √© um site. √â sua presen√ßa inegoci√°vel no digital."
</signature>

<channel_adaptation>
CANAL (PERSONALIZA√á√ÉO EMOCIONAL POR PLATAFORMA):

Instagram:
- Tom: Visual, descontra√≠do, com emojis estrat√©gicos
- Linguagem: "E a√≠! üëã", "Deslize para ver mais ‚û°Ô∏è", "Isso aqui t√° incr√≠vel üî•"
- Foco: Est√©tica, stories, visual impactante
- CTA: "Deslize para ver mais" ou "Salva esse post"

WhatsApp:
- Tom: Direto, pessoal, sem firulas
- Linguagem: "Oi", "Vamos fechar?", "Te mando agora"
- Foco: Rapidez, praticidade, fechamento r√°pido
- CTA: "Quer que eu monte pra voc√™ agora?"

API/Outros:
- Tom: Profissional mas pr√≥ximo
- Linguagem: "Ol√°", "Vamos conversar?", "Proposta personalizada"
- Foco: Efici√™ncia, clareza, valor
- CTA: "Vamos conversar?"
</channel_adaptation>

<lead_segmentation>
MICRO-SEGMENTA√á√ÉO DE LEADS:

Lead T√©cnico:
- Foco: Performance, escalabilidade, arquitetura t√©cnica
- Linguagem: T√©cnica mas acess√≠vel
- Valor: "Sistema robusto que escala"
- Exemplo: "Arquitetura preparada para crescer sem quebrar"

Lead Est√©tico:
- Foco: Design, experi√™ncia visual, identidade de marca
- Linguagem: Visual e emocional
- Valor: "Presen√ßa visual que converte"
- Exemplo: "Design que fala direto com seu p√∫blico"

Lead Gestor:
- Foco: ROI, resultados mensur√°veis, gest√£o de equipe
- Linguagem: Estrat√©gica e orientada a resultados
- Valor: "Solu√ß√£o que entrega resultados"
- Exemplo: "Sistema que sua equipe vai usar e voc√™ vai medir"
</lead_segmentation>

<visual_strategy>
ESTRAT√âGIA VISUAL:

- SEMPRE use send_portfolio_visual quando apresentar propostas ou quando lead perguntar sobre exemplos/portf√≥lio
- O material visual aumenta percep√ß√£o de valor e cria autoridade imediata
- Combine o link visual com copy de impacto + urg√™ncia + valor percebido
- Mantenha tom curto, impactante, confiante ‚Äî n√£o seja gen√©rico
- Adapte linguagem ao canal: Instagram = mais visual, linguagem de stories; WhatsApp = mais direta, informal
</visual_strategy>

<proposal_logic>
PROPOSTAS:
- Padr√£o: gere proposta customizada (IQAI + IPFS) e envie como link √∫nico (proposal_type = "custom")
- Se o lead estiver com pressa ou pedir algo r√°pido, use o template pronto: ${PROPOSAL_TEMPLATE_LINK} (proposal_type = "template")
- Sempre ofere√ßa a escolha: "Quer a proposta custom exclusiva ou prefere o modelo r√°pido?"
- Mesmo ap√≥s enviar o template, deixe porta aberta para gerar a vers√£o custom se o lead quiser algo espec√≠fico para a empresa dele
</proposal_logic>

<frustration_detection>
DETEC√á√ÉO DE FRUSTRA√á√ÉO DO USU√ÅRIO:

Se o usu√°rio disser algo como:
- "j√° respondi isso"
- "voc√™ perguntou isso 3 vezes"
- "voc√™ est√° perdido?"
- "sabe me dizer porque est√° me perguntando v√°rias vezes sobre X?"
- Qualquer reclama√ß√£o sobre repeti√ß√£o

A√á√ÉO IMEDIATA:
1. RECONHE√áA o erro: "Desculpa pela repeti√ß√£o! Vi que voc√™ j√° mencionou [X]. Vamos avan√ßar."
2. N√ÉO explique ou justifique demais - apenas reconhe√ßa e avance
3. Use as informa√ß√µes que J√Å TEM no hist√≥rico
4. Avance para a PR√ìXIMA etapa (n√£o fa√ßa mais perguntas de diagn√≥stico se j√° tem as informa√ß√µes)
5. Se j√° tem objetivo + identidade + prazo ‚Üí V√Å DIRETO PARA PROPOSTA
</frustration_detection>

<context_detection>
DETEC√á√ÉO INTELIGENTE DE CONTEXTO:

URLs e Links:
- Se o usu√°rio mencionar URL (http://, https://, .eth.link, .com, .xyz, etc) ‚Üí √â UM SITE/PROJETO
- N√ÉO confunda com token ou blockchain - URLs s√£o sempre sites/projetos
- Use a URL para entender o contexto: "Vi que voc√™ tem o site [URL]. Vamos modernizar ele?"

Nomes e Refer√™ncias:
- "Mello", "MELL√ò" ‚Üí Pode ser nome do usu√°rio ou refer√™ncia pessoal
- Se perguntarem "Quem √© X?" ‚Üí Responda sobre X, n√£o pergunte de novo
- Use nomes mencionados para personalizar a conversa

Informa√ß√µes J√° Coletadas:
- Se o usu√°rio disse "quero atualizar meu site" ‚Üí OBJETIVO: atualizar site (N√ÉO pergunte de novo)
- Se o usu√°rio disse "j√° tenho identidade visual" ‚Üí TEM identidade (N√ÉO pergunte de novo)
- Se o usu√°rio disse "15 dias" ou "urgente" ‚Üí PRAZO conhecido (N√ÉO pergunte de novo)
- Se o usu√°rio disse "webapp" ‚Üí TIPO: webapp (N√ÉO pergunte de novo)

L√≥gica de Avan√ßo:
- Se coletou objetivo + identidade + prazo ‚Üí PROPOSTA
- Se coletou 2 de 3 ‚Üí Fa√ßa a pergunta que falta (UMA VEZ)
- Se coletou 1 de 3 ‚Üí Fa√ßa a pr√≥xima pergunta (UMA VEZ)
- Se coletou 0 de 3 ‚Üí Fa√ßa a primeira pergunta (s√≥ se n√£o mencionado)
</context_detection>
    `;

	// Adicionar contexto personalizado se dispon√≠vel
	if (context.user?.name) {
		instruction += `\n\nCONTEXTO DO USU√ÅRIO:\n- Nome: ${context.user.name}`;
	}
	if (context.user?.location) {
		instruction += `\n- Localiza√ß√£o: ${context.user.location}`;
	}
	if (context.projectStage) {
		instruction += `\n- Est√°gio do projeto: ${context.projectStage}`;
	}
	
	// Adicionar hist√≥rico da conversa se dispon√≠vel (formato GPT-5)
	if (context.history && Array.isArray(context.history) && context.history.length > 0) {
		instruction += `\n\n<conversation_history>\n`;
		instruction += `Hist√≥rico da conversa (use para manter contexto e n√£o repetir):\n\n`;
		context.history.forEach((msg: any, index: number) => {
			if (msg.role && msg.content) {
				instruction += `${index + 1}. ${msg.role === "user" ? "[USER]" : "[YOU]"}: ${msg.content}\n`;
			}
		});
		instruction += `\nREGRAS CR√çTICAS COM BASE NO HIST√ìRICO:\n`;
		instruction += `- Se o usu√°rio j√° mencionou interesse em site/projeto, N√ÉO pergunte "o que te trouxe aqui" novamente\n`;
		instruction += `- Se o usu√°rio j√° respondeu uma pergunta de diagn√≥stico, N√ÉO fa√ßa a mesma pergunta novamente\n`;
		instruction += `- Se o usu√°rio disse "nada" ou demonstrou desinteresse, mude de abordagem imediatamente\n`;
		instruction += `- Use as informa√ß√µes do hist√≥rico para fazer perguntas mais espec√≠ficas e avan√ßadas\n`;
		instruction += `- Se o usu√°rio reclamou de repeti√ß√£o (ex: "j√° respondi isso", "voc√™ perguntou isso 3 vezes"), RECONHE√áA o erro e AVANCE\n`;
		instruction += `- Se o usu√°rio mencionou URL (http://, https://, .eth.link), √© um SITE/PROJETO, n√£o token\n`;
		instruction += `- Se o usu√°rio mencionou "Mello" ou "MELL√ò", pode ser nome dele - use isso no contexto\n`;
		instruction += `\nVERIFICA√á√ÉO ANTES DE PERGUNTAR:\n`;
		instruction += `1. Objetivo j√° mencionado? (site, webapp, atualizar, modernizar) ‚Üí PULE pergunta (a)\n`;
		instruction += `2. Identidade visual j√° respondida? (j√° tenho, do zero, tenho identidade) ‚Üí PULE pergunta (b)\n`;
		instruction += `3. Prazo j√° mencionado? (15 dias, urgente, 1 m√™s) ‚Üí PULE pergunta (c)\n`;
		instruction += `4. Se tem todas as 3 informa√ß√µes ‚Üí V√Å DIRETO PARA PROPOSTA\n`;
		instruction += `</conversation_history>\n`;
	}

	return await AgentBuilder.create("flowcloser")
		.withModel(model)
		.withDescription(
			"Closer digital especializado em vendas de presen√ßa digital",
		)
		.withInstruction(instruction)
		.withTools(
			qualifyLeadTool,
			createMicroOfferTool,
			getChannelContextTool,
			searchLeadHistoryTool,
			checkNeoflowTokenTool,
			sendPortfolioVisualTool,
		)
		.withSessionService(sessionService, {
			appName: "neoflow",
			userId,
			state: {
				channel,
				lead_intent: "unknown",
				lead: {
					intent: "unknown",
					painPoints: [],
					source: channel,
				},
				micro_offers: [],
				...context, // Merge contexto adicional no estado
			},
		})
		.withBeforeModelCallback(guardrailsCallback)
		.build();
}

export async function agent() {
	const model = process.env.LLM_MODEL || "gpt-4o";
	return await createAgentWithModel(model);
}

interface AskOptions {
	channel?: string;
	userId?: string;
	context?: AgentContext;
}

/**
 * Detecta o est√°gio do lead baseado na mensagem
 */
function detectLeadStage(message: string): "opening" | "diagnosis" | "proposal" | "conversion" | "closed" {
	const msg = message.toLowerCase();
	
	if (msg.includes("quero") || msg.includes("preciso") || msg.includes("or√ßamento") || msg.includes("pre√ßo")) {
		return "conversion";
	}
	if (msg.includes("como") || msg.includes("quando") || msg.includes("quanto tempo") || msg.includes("prazo")) {
		return "proposal";
	}
	if (msg.includes("sim") || msg.includes("ok") || msg.includes("vamos") || msg.includes("fechar")) {
		return "closed";
	}
	if (msg.includes("projeto") || msg.includes("site") || msg.includes("app") || msg.includes("sistema")) {
		return "diagnosis";
	}
	
	return "opening";
}

export async function askWithFallback(
	userMessage: string,
	options: AskOptions = {},
): Promise<string> {
	const model = process.env.LLM_MODEL || "gpt-4o";
	const fallbackModel = process.env.LLM_MODEL_FALLBACK || "gemini-2.5-flash";
	const { channel, userId, context = {} } = options;

	// Merge contexto
	const agentContext: AgentContext = {
		channel: channel || context.channel || "instagram",
		userId: userId || context.userId,
		...context,
	};

	let agentResponse: string;
	let usedModel = model;
	let fallbackUsed = false;

	try {
		console.log(`ü§ñ Using primary model: ${model}`);
		
		// Detectar est√°gio do lead baseado na mensagem
		const leadStage = detectLeadStage(userMessage);
		await logLeadStage(leadStage, {
			channel: agentContext.channel,
			userId: agentContext.userId,
		});

		// Disponibilizar contexto para tools (para Conversions API)
		(globalThis as any).currentUserId = agentContext.userId;
		(globalThis as any).currentChannel = agentContext.channel;
		
		const { runner } = await createAgentWithModel(model, agentContext);
		agentResponse = await runner.ask(userMessage);
		
		// Verificar se a resposta cont√©m erro (ADK pode retornar erro como string)
		if (typeof agentResponse === "string" && agentResponse.startsWith("Error:")) {
			throw new Error(agentResponse);
		}

		// Callback p√≥s-resposta (simulado, j√° que ADK n√£o tem afterModelCallback nativo)
		await afterModelCallback({
			callbackContext: {
				state: agentContext as any,
				input: { message: userMessage },
			} as any,
			llmRequest: { model } as any,
			llmResponse: agentResponse as any,
		});

		// Log da resposta com detec√ß√£o de portf√≥lio
		await logAgentResponse(agentResponse, {
			stage: "Response",
			channel: agentContext.channel,
			userId: agentContext.userId,
			model: usedModel,
		});
	} catch (error) {
		console.warn(`‚ö†Ô∏è Primary model (${model}) failed. Falling back to: ${fallbackModel}`);
		console.error("Error:", error instanceof Error ? error.message : String(error));
		
		// Log do fallback
		if (error instanceof Error) {
			await logModelFallback(model, fallbackModel, error);
		}
		
		try {
			const { runner } = await createAgentWithModel(fallbackModel, agentContext);
			agentResponse = await runner.ask(userMessage);
			usedModel = fallbackModel;
			fallbackUsed = true;
			
			// Verificar novamente se h√° erro no fallback
			if (typeof agentResponse === "string" && agentResponse.startsWith("Error:")) {
				throw new Error(agentResponse);
			}
			
			console.log(`‚úÖ Fallback model (${fallbackModel}) succeeded`);

			// Callback p√≥s-resposta para fallback
			await afterModelCallback({
				callbackContext: {
					state: agentContext as any,
					input: { message: userMessage },
				} as any,
				llmRequest: { model: fallbackModel } as any,
				llmResponse: agentResponse as any,
			});

			// Log da resposta com fallback
			await logAgentResponse(agentResponse, {
				stage: "Response",
				channel: agentContext.channel,
				userId: agentContext.userId,
				model: usedModel,
				fallbackUsed: true,
			});
		} catch (fallbackError) {
			console.error("‚ùå Fallback model also failed:", fallbackError);
			throw new Error(
				`Both models failed. Primary: ${error instanceof Error ? error.message : String(error)}. Fallback: ${fallbackError instanceof Error ? fallbackError.message : String(fallbackError)}`
			);
		}
	}

	return typeof agentResponse === "string" ? agentResponse : JSON.stringify(agentResponse);
}
